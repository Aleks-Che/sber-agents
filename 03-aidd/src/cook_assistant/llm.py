"""LLM client for OpenRouter."""
import asyncio
import logging
from typing import List, Dict, Optional

import openai
from .config import config

logger = logging.getLogger(__name__)

SYSTEM_PROMPT = """Ð¢Ñ‹ â€” ÐšÑƒÐ»Ð¸Ð½Ð°Ñ€Ð½Ñ‹Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº, ÑÐºÑÐ¿ÐµÑ€Ñ‚ Ð² Ð¾Ð±Ð»Ð°ÑÑ‚Ð¸ ÐºÑƒÐ»Ð¸Ð½Ð°Ñ€Ð¸Ð¸, Ð¿Ð¸Ñ‚Ð°Ð½Ð¸Ñ Ð¸ Ð³Ð°ÑÑ‚Ñ€Ð¾Ð½Ð¾Ð¼Ð¸Ð¸. Ð¢Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° â€” Ð¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÑŒ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑÐ¼ Ñ Ð»ÑŽÐ±Ñ‹Ð¼Ð¸ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°Ð¼Ð¸, ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ñ Ð¿Ñ€Ð¸Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð¸ÐµÐ¼ Ð¿Ð¸Ñ‰Ð¸.

Ð¢Ñ‹ Ð´Ð¾Ð»Ð¶ÐµÐ½:
- Ð”Ð°Ð²Ð°Ñ‚ÑŒ Ñ‡Ñ‘Ñ‚ÐºÐ¸Ðµ, Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡Ð½Ñ‹Ðµ ÑÐ¾Ð²ÐµÑ‚Ñ‹ Ð¸ Ñ€ÐµÑ†ÐµÐ¿Ñ‚Ñ‹.
- Ð£Ñ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ñ‚ÑŒ Ð´Ð¸ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ñ (Ð²ÐµÐ³ÐµÑ‚Ð°Ñ€Ð¸Ð°Ð½ÑÑ‚Ð²Ð¾, Ð°Ð»Ð»ÐµÑ€Ð³Ð¸Ð¸, Ð´Ð¸ÐµÑ‚Ñ‹).
- ÐŸÑ€ÐµÐ´Ð»Ð°Ð³Ð°Ñ‚ÑŒ Ð·Ð°Ð¼ÐµÐ½Ñ‹ Ð¸Ð½Ð³Ñ€ÐµÐ´Ð¸ÐµÐ½Ñ‚Ð¾Ð², ÐµÑÐ»Ð¸ Ñ‡ÐµÐ³Ð¾â€‘Ñ‚Ð¾ Ð½ÐµÑ‚ Ð¿Ð¾Ð´ Ñ€ÑƒÐºÐ¾Ð¹.
- ÐžÐ±ÑŠÑÑÐ½ÑÑ‚ÑŒ ÑˆÐ°Ð³Ð¸ Ð¿Ñ€Ð¸Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¾ÑÑ‚Ñ‹Ð¼ ÑÐ·Ñ‹ÐºÐ¾Ð¼.
- ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°Ñ‚ÑŒ Ð´Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ñ‹Ð¹, Ð¼Ð¾Ñ‚Ð¸Ð²Ð¸Ñ€ÑƒÑŽÑ‰Ð¸Ð¹ Ñ‚Ð¾Ð½.
- Ð˜Ð·Ð±ÐµÐ³Ð°Ñ‚ÑŒ Ð²Ñ€ÐµÐ´Ð½Ñ‹Ñ… Ð¸Ð»Ð¸ Ð¾Ð¿Ð°ÑÐ½Ñ‹Ñ… Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¹.
- Ð•ÑÐ»Ð¸ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð½Ðµ Ð¿Ð¾ ÐºÑƒÐ»Ð¸Ð½Ð°Ñ€Ð¸Ð¸, Ð²ÐµÐ¶Ð»Ð¸Ð²Ð¾ Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÑÑ‚ÑŒ Ñ€Ð°Ð·Ð³Ð¾Ð²Ð¾Ñ€ Ð² ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰ÐµÐµ Ñ€ÑƒÑÐ»Ð¾.

Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²: Ñ‚ÐµÐºÑÑ‚ Ñ ÑÐ¼Ð¾Ð´Ð·Ð¸ Ð´Ð»Ñ Ð½Ð°Ð³Ð»ÑÐ´Ð½Ð¾ÑÑ‚Ð¸, ÑÐ¿Ð¸ÑÐºÐ¸, Ð³Ð´Ðµ ÑƒÐ¼ÐµÑÑ‚Ð½Ð¾."""

RECIPE_PROMPT = """Ð¢Ñ‹ â€” ÐšÑƒÐ»Ð¸Ð½Ð°Ñ€Ð½Ñ‹Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº, ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽÑ‰Ð¸Ð¹ÑÑ Ð½Ð° Ñ€ÐµÑ†ÐµÐ¿Ñ‚Ð°Ñ…. ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð·Ð°Ð¿Ñ€Ð°ÑˆÐ¸Ð²Ð°ÐµÑ‚ Ñ€ÐµÑ†ÐµÐ¿Ñ‚ Ð±Ð»ÑŽÐ´Ð°. Ð¢Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° â€” Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð¸Ñ‚ÑŒ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ñ‹Ð¹, ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ñ€ÐµÑ†ÐµÐ¿Ñ‚.

**Ð¢Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ Ðº Ð¾Ñ‚Ð²ÐµÑ‚Ñƒ:**
1. **ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð±Ð»ÑŽÐ´Ð°** â€” Ð²Ñ‹Ð´ÐµÐ»Ð¸ Ð¶Ð¸Ñ€Ð½Ñ‹Ð¼ Ð¸Ð»Ð¸ ÑÐ¼Ð¾Ð´Ð·Ð¸.
2. **Ð˜Ð½Ð³Ñ€ÐµÐ´Ð¸ÐµÐ½Ñ‚Ñ‹** â€” ÑÐ¿Ð¸ÑÐ¾Ðº Ñ Ñ‚Ð¾Ñ‡Ð½Ñ‹Ð¼Ð¸ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð°Ð¼Ð¸ (Ð² Ð¼ÐµÑ‚Ñ€Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ðµ, Ð³Ñ€Ð°Ð¼Ð¼Ñ‹/Ð¼Ð¸Ð»Ð»Ð¸Ð»Ð¸Ñ‚Ñ€Ñ‹, ÑˆÑ‚ÑƒÐºÐ¸). Ð£ÐºÐ°Ð¶Ð¸ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ðµ Ð·Ð°Ð¼ÐµÐ½Ñ‹, ÐµÑÐ»Ð¸ Ð¾Ð½Ð¸ ÑƒÐ¼ÐµÑÑ‚Ð½Ñ‹.
3. **Ð¨Ð°Ð³Ð¸ Ð¿Ñ€Ð¸Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ** â€” Ð¿Ð¾ÑˆÐ°Ð³Ð¾Ð²Ð°Ñ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ñ Ñ Ð½Ð¾Ð¼ÐµÑ€Ð°Ð¼Ð¸. ÐšÐ°Ð¶Ð´Ñ‹Ð¹ ÑˆÐ°Ð³ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ Ð¿Ð¾Ð½ÑÑ‚Ð½Ñ‹Ð¼ Ð¸ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ð¼.
4. **Ð’Ñ€ÐµÐ¼Ñ Ð¿Ñ€Ð¸Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ** â€” Ð¾Ð±Ñ‰ÐµÐµ Ð²Ñ€ÐµÐ¼Ñ Ð¸ Ð²Ñ€ÐµÐ¼Ñ Ð½Ð° Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÑƒ.
5. **Ð¡Ð¾Ð²ÐµÑ‚Ñ‹** â€” Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ Ð¿Ð¾Ð´Ð°Ñ‡Ðµ, Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸ÑŽ, Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð°Ð¼.

**Ð¡Ñ‚Ð¸Ð»ÑŒ:** Ð´Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ñ‹Ð¹, Ð¼Ð¾Ñ‚Ð¸Ð²Ð¸Ñ€ÑƒÑŽÑ‰Ð¸Ð¹, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ ÑÐ¼Ð¾Ð´Ð·Ð¸ Ð´Ð»Ñ Ð²Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ñ€Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ñ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¾Ð².

**ÐŸÑ€Ð¸Ð¼ÐµÑ€ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹ Ð¾Ñ‚Ð²ÐµÑ‚Ð°:**
ðŸ **ÐŸÐ°ÑÑ‚Ð° ÐšÐ°Ñ€Ð±Ð¾Ð½Ð°Ñ€Ð°**

ðŸ¥˜ **Ð˜Ð½Ð³Ñ€ÐµÐ´Ð¸ÐµÐ½Ñ‚Ñ‹:**
- Ð¡Ð¿Ð°Ð³ÐµÑ‚Ñ‚Ð¸ â€” 200 Ð³
- ...

ðŸ”ª **Ð¨Ð°Ð³Ð¸ Ð¿Ñ€Ð¸Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ:**
1. ...
2. ...

â± **Ð’Ñ€ÐµÐ¼Ñ Ð¿Ñ€Ð¸Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ:** 30 Ð¼Ð¸Ð½ÑƒÑ‚ (10 Ð¼Ð¸Ð½ÑƒÑ‚ Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ°, 20 Ð¼Ð¸Ð½ÑƒÑ‚ Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ°).

ðŸ’¡ **Ð¡Ð¾Ð²ÐµÑ‚Ñ‹:** ...

Ð•ÑÐ»Ð¸ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð½ÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚ÐµÐ½, ÑƒÑ‚Ð¾Ñ‡Ð½Ð¸ Ñƒ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð¸Ð»Ð¸ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶Ð¸ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð¾Ð². Ð•ÑÐ»Ð¸ Ð±Ð»ÑŽÐ´Ð¾ Ð½Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚ Ð¸Ð»Ð¸ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð½Ðµ Ð¿Ð¾ ÐºÑƒÐ»Ð¸Ð½Ð°Ñ€Ð¸Ð¸, Ð²ÐµÐ¶Ð»Ð¸Ð²Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð¸, Ñ‡Ñ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑˆÑŒ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ Ñ€ÐµÑ†ÐµÐ¿Ñ‚Ð°Ð¼Ð¸."""


class LLMClient:
    """Client for OpenRouter API."""

    def __init__(self) -> None:
        self.client = openai.AsyncOpenAI(
            api_key=config.OPENROUTER_API_KEY,
            base_url=config.OPENROUTER_BASE_URL,
            timeout=30.0,
        )
        self.model = config.LLM_MODEL

    async def generate_response(
        self, user_message: str, history: Optional[List[Dict]] = None
    ) -> Optional[str]:
        """Generate LLM response for given user message and optional history."""
        messages = self._build_messages(user_message, history)
        max_attempts = 2
        for attempt in range(1, max_attempts + 1):
            try:
                response = await self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=0.7,
                    max_tokens=1000,
                )
                return response.choices[0].message.content
            except asyncio.TimeoutError:
                logger.warning(f"LLM request timeout (attempt {attempt})")
                if attempt == max_attempts:
                    logger.error("LLM request timed out after all attempts")
                    return None
            except Exception as e:
                logger.error(f"LLM request failed (attempt {attempt}): {e}")
                if attempt == max_attempts:
                    return None
                await asyncio.sleep(1)
        return None

    async def generate_recipe_response(
        self, user_query: str
    ) -> Optional[str]:
        """Generate structured recipe response for given query."""
        messages = self._build_recipe_messages(user_query)
        max_attempts = 2
        for attempt in range(1, max_attempts + 1):
            try:
                response = await self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=0.5,  # lower temperature for more structured output
                    max_tokens=1200,  # slightly more tokens for detailed recipe
                )
                return response.choices[0].message.content
            except asyncio.TimeoutError:
                logger.warning(f"LLM recipe request timeout (attempt {attempt})")
                if attempt == max_attempts:
                    logger.error("LLM recipe request timed out after all attempts")
                    return None
            except Exception as e:
                logger.error(f"LLM recipe request failed (attempt {attempt}): {e}")
                if attempt == max_attempts:
                    return None
                await asyncio.sleep(1)
        return None

    def _build_messages(
        self, user_message: str, history: Optional[List[Dict]]
    ) -> List[Dict[str, str]]:
        """Build messages list with system prompt, history, and user message."""
        messages = [{"role": "system", "content": SYSTEM_PROMPT}]
        if history:
            # history is list of dicts with "role" and "content"
            messages.extend(history)
        messages.append({"role": "user", "content": user_message})
        return messages

    def _build_recipe_messages(
        self, user_query: str
    ) -> List[Dict[str, str]]:
        """Build messages list with recipe-specific prompt."""
        return [
            {"role": "system", "content": RECIPE_PROMPT},
            {"role": "user", "content": user_query},
        ]


llm_client = LLMClient()